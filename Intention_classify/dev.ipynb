{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0b2b1d-e2a4-4eda-82a4-4688e16c5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os.path\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional\n",
    "\n",
    "from loguru import logger\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "logger.add(\"out.log\")\n",
    "import numpy\n",
    "import requests\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LR = 1e-5\n",
    "\n",
    "model_path = \"./Model/chinese-roberta-wwm-ext\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = torch.load(\"./Model_save/classify_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908e1e56-81ae-473d-b6f9-3f19203f9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClassify(Dataset):\n",
    "    def __init__(self, question):\n",
    "        self.data_list = [{\"sentence\":question,\"label\":0}]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data_list[index]\n",
    "        item = DataItem(**item)\n",
    "        content = item.sentence\n",
    "        return content, item.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "\n",
    "def collator_fn(batch):\n",
    "    batch = numpy.array(batch)\n",
    "\n",
    "    data_batch = batch[:, 0]\n",
    "    label_batch = numpy.array(batch[:, 1], dtype=int)\n",
    "    data_batch = tokenizer(data_batch.tolist(), max_length=256, padding=True, truncation=True,\n",
    "                           return_tensors=\"pt\").to(DEVICE)\n",
    "    return data_batch, torch.tensor(label_batch, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "@dataclass\n",
    "class DataItem:\n",
    "    sentence: str\n",
    "    label: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3a40ae-6cc7-4b7a-9c18-b8bd7b41efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "闲聊\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2id = {\"闲聊\":0,\"咨询\":1,\"转人工\":2}\n",
    "id2word = {0:\"闲聊\",1:\"咨询\",2:\"转人工\"}\n",
    "question = \"早上好\"\n",
    "test_data_loader = DataLoader(DatasetClassify(question), batch_size=32, shuffle=False,\n",
    "                             collate_fn=collator_fn)\n",
    "model.eval()\n",
    "pred_label = []\n",
    "for item, label in tqdm(test_data_loader, position=0, leave=True):\n",
    "    model.eval()\n",
    "    output = model(**item)\n",
    "    pre_label = output.logits.detach().cpu().numpy()\n",
    "    pre_label = np.argmax(pre_label, axis=1)\n",
    "    print(id2word[int(pre_label[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
